# spark dataframes 2
## План выполнения задач
Любой job имеет под собой план выполнения, который генерируется на основе написанного запроса. План запроса содержит в себе операторы которые потом генерируются в `Java` код.

План выполнения доступен в двух видах:
- метод `explain()` у датафрейма
- на вкладке SQL в Spark UI

Любая оптимизация сосредоточена на нескольких вещах:
- снижение количества shuffle (т.к. он задействует и сетевые соединения, при перемещении блоков данных между воркерами, и дисковое пространство при сохранение нового stage)
- фильтрование данных на уровне источника (для работы с как можно меньшим объемом данных)

>**Parser Logical Plan** - просто отражение того что мы написали в коде  
>**Analyzed Logical Plan** - происходит проверка на наличия колонок и правильности применения функций (по типам данных например)  
>**Optimized Logical Plan** - оптимизация запроса  
>**Physical Plan** - сам набор физических операций
>**Adaptive plan** - появился в spark3 (пока не знаю как работает)

Также можно выгрузить планы запроса, например
`df.queryExecution.executedPlan.toJSON`

![alt text](./picture/phisical_plan_0.png)

![alt text](./picture/phisical_plan_1.png)

44:00